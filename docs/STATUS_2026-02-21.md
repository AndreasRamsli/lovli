# Status Update (2026-02-21)

This note documents the routing reranker investigation and the hybrid embedding routing fix implemented during this session.

## Problem: High contamination rate (69% unexpected citations)

Validation sweep results showed:

| Metric | Value |
|---|---|
| `unexpected_citation_rate` | 0.69 |
| `routing_uncertain_count` | 18 / 20 |
| `fallback_stage2_unfiltered_count` | 17 / 20 |
| `route_miss_expected_law_rate` | 0.80 |
| `recall_at_k` | 0.80 (retrieval itself fine) |

All 20 eval questions target husleieloven (`nl-19990326-017`), which is present in the law catalog. The contamination was not from cross-law leakage but from unfiltered retrieval flooding the context with articles from all laws.

## Root cause analysis — three compounding issues

### Issue 1: Wrong CrossEncoder parameter name (silent)
`chain.py` used `automodel_args={"torch_dtype": torch.float32}` to force fp32 on GPU. In `sentence-transformers>=5`, this parameter was renamed to `model_kwargs`. The old name triggered a deprecation warning but was silently ignored — the dtype was never applied.

**Fix:** renamed to `model_kwargs`.

### Issue 2: Stale precompute cache (masked the fix)
The sweep script's precompute cache key did not include reranker config fields. A prior run's cached candidates (with collapsed scores) were reused even after code changes. Combined with Issue 1, the fp32 fix had no observable effect in the next run.

**Fix:** added `reranker_model` and `law_routing_reranker_enabled` to the cache key. Added explicit cache clear to the notebook preflight cell.

### Issue 3: Fundamental reranker task mismatch (root cause)
Even with correct fp32, `bge-reranker-v2-m3` produced near-zero logits for all law routing pairs, regardless of dtype. Example for query "Hvor mye kan utleier kreve i depositum?":

```
sf-20140613-0724: law_reranker_score = 0.5001142
sf-20090602-0628: law_reranker_score = 0.5000591
nl-19650625-001:  law_reranker_score = 0.5000459
nl-20170616-065:  law_reranker_score = 0.5000383
```

All 16 scored candidates cluster within 0.0001 of each other. This is a **task mismatch**, not a numeric precision issue:

- `bge-reranker-v2-m3` is a cross-encoder trained on (query, short passage) pairs for document reranking.
- Law routing feeds it (query, full catalog summary) — long, generic legal descriptions.
- The model cannot find a relevance signal between a specific question and a 400-character description of an entire law.
- Result: `is_uncertain=True` for 18/20 questions → `stage2_unfiltered` fallback → retrieves from all laws → 69% unexpected citations.

The document reranker works correctly for article-level scoring (`avg_top_score=0.661`) because it operates on focused article text, not catalog summaries.

## Solution: BGE-M3 embedding hybrid routing

**Architecture:** Replace cross-encoder law routing with cosine similarity over BGE-M3 embeddings, blended with lexical token overlap.

**At startup:**
- Embed all 4427 law `routing_summary_text` strings using the already-loaded BGE-M3 model.
- Store as float vectors in the catalog entry dicts.
- Cost: ~2-4s on GPU, ~30-90s on CPU (see known issue below).

**At query time:**
- Embed query with `embed_query()`.
- Compute cosine similarity against all law embeddings.
- Blend: `score = embedding_sim * 0.7 + normalized_lexical * 0.3`
- Store as `law_reranker_score` — all downstream logic (confidence thresholds, uncertainty detection, alignment map) is unchanged.

**Why BGE-M3 is the right model here:** It is a bi-encoder trained for semantic retrieval — computing similarity between a query and a corpus of documents. This is exactly the law routing task. The cross-encoder (`bge-reranker-v2-m3`) is designed for re-scoring a short list of candidates where query and passage are jointly encoded — a different task.

**Why keep the lexical component (0.3 weight):** Direct keyword matches (e.g., "husleieloven" in the query) are high-precision signal. The lexical boost ensures laws with explicit name mentions are not outranked by semantically-similar but wrong laws.

## Routing priority order (current)

```
1. Embedding hybrid (default, LAW_ROUTING_EMBEDDING_ENABLED=true)
2. Cross-encoder     (opt-in, LAW_ROUTING_RERANKER_ENABLED=true)
3. Lexical only      (both disabled)
```

The cross-encoder path is kept for future use if a catalog-specific reranker is ever trained.

## New configuration settings

| Setting | Default | Description |
|---|---|---|
| `LAW_ROUTING_EMBEDDING_ENABLED` | `true` | Enable BGE-M3 hybrid routing |
| `LAW_ROUTING_EMBEDDING_WEIGHT` | `0.7` | Embedding vs lexical blend weight |
| `LAW_ROUTING_EMBEDDING_TEXT_FIELD` | `routing_summary_text` | Which catalog field to embed |
| `LAW_ROUTING_RERANKER_ENABLED` | `false` | Cross-encoder routing (disabled) |

## Known issue: CPU startup cost

Embedding 4427 laws on CPU with BGE-M3 (~570M parameters) takes approximately 30-90 seconds. On GPU (H100/A100/T4) this is 2-4 seconds — acceptable.

**Planned fix:** Serialize the embedding index to disk on first run (numpy array + catalog SHA256 checksum). Subsequent starts load from disk in ~0.5s. Invalidation is automatic when the catalog changes. This is tracked as a TODO in `chain.py`.

## Expected metrics improvement

| Metric | Before | Expected after |
|---|---|---|
| `routing_uncertain_count` | 18/20 | ~1-2/20 |
| `fallback_stage2_unfiltered_count` | 17/20 | ~0-2/20 |
| `unexpected_citation_rate` | 0.69 | significant reduction |
| `route_miss_expected_law_rate` | 0.80 | ~0.1-0.2 |

## Files changed

| File | Change |
|---|---|
| `src/lovli/routing.py` | Added `build_law_embedding_index()`, `score_law_candidates_embedding()` |
| `src/lovli/chain.py` | Embedding index build at catalog load; routing dispatch with priority order; `model_kwargs` fix |
| `src/lovli/config.py` | Three new `law_routing_embedding_*` settings; `law_routing_reranker_enabled` |
| `scripts/sweep_retrieval_thresholds.py` | Cache key includes reranker config; `HF_HUB_OFFLINE` after model load |
| `notebooks/validate_reindex_h100_colab.ipynb` | Cache clear in preflight; embedding env vars; `HF_TOKEN` prompt |
| `tests/test_chain.py` | 5 new unit tests for embedding routing functions |
| `.env` / `.env.example` | New routing settings documented |

## Commits

- `7d846fc` — Initial fp32 fix attempt + HF offline mode (incomplete — wrong param name, stale cache)
- `37bbf97` — `model_kwargs` rename + disable cross-encoder routing + cache key fix + notebook cache clear
- `f258bc2` — BGE-M3 embedding hybrid routing implementation
- `5c8efc7` — CPU startup cost documentation + `.env` updates
