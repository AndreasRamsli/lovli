{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lovli - Retrieval Threshold Sweep (Colab)\n",
        "\n",
        "This notebook runs retrieval-only tuning in Colab using the production sweep script.\n",
        "\n",
        "## What it does\n",
        "- Loads the project and dependencies\n",
        "- Uses `scripts/sweep_retrieval_thresholds.py` as single source of truth\n",
        "- Runs compact 5-dimension sweep:\n",
        "  - `retrieval_k_initial`\n",
        "  - `reranker_confidence_threshold`\n",
        "  - `reranker_min_doc_score`\n",
        "  - `reranker_ambiguity_min_gap`\n",
        "  - `reranker_ambiguity_top_score_ceiling`\n",
        "- Saves results to `eval/retrieval_sweep_results.json`\n",
        "\n",
        "## Selection objective\n",
        "- Leakage-first: improve off-topic cleanliness first, then recall/coverage/precision.\n",
        "\n",
        "## Expected outputs\n",
        "- Ranked sweep table in notebook output\n",
        "- JSON file with all combinations and metrics"
      ],
      "id": "3b00dedc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# If running in Colab, clone your repo first (skip if already cloned).\n",
        "import os\n",
        "if not os.path.exists(\"/content/lovli\"):\n",
        "    !git clone https://github.com/AndreasRamsli/lovli.git\n",
        "%cd /content/lovli\n",
        "\n",
        "# Satisfy google-colab's requests pin to avoid dependency conflicts\n",
        "!pip install -q \"requests==2.32.4\"\n",
        "!pip install -q -e ."
      ],
      "execution_count": null,
      "outputs": [],
      "id": "f8aac167"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "import itertools\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Reduce noisy tracing during local experiments\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"false\"\n",
        "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
        "\n",
        "# Find repo root: Colab clone is /content/lovli; fallback to cwd if running from repo\n",
        "ROOT_DIR = Path(\"/content/lovli\")\n",
        "if not (ROOT_DIR / \"src\" / \"lovli\").exists():\n",
        "    for cand in [Path.cwd(), Path.cwd().parent]:\n",
        "        if (cand / \"src\" / \"lovli\").exists():\n",
        "            ROOT_DIR = cand\n",
        "            break\n",
        "if not (ROOT_DIR / \"src\" / \"lovli\").exists():\n",
        "    raise FileNotFoundError(\n",
        "        \"lovli package not found. Run the setup cell above first (clone + pip install), \"\n",
        "        \"then Runtime > Restart runtime, then run from this cell.\"\n",
        "    )\n",
        "if str(ROOT_DIR / \"src\") not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT_DIR / \"src\"))\n",
        "\n",
        "from lovli.chain import LegalRAGChain\n",
        "from lovli.config import get_settings\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "2be9fbd1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Paste credentials here for quick Colab runs.\n",
        "OPENROUTER_API_KEY = \"\"  # e.g. \"sk-or-v1-...\" (optional for sweep, but keep non-empty)\n",
        "QDRANT_URL = \"\"          # e.g. \"https://<cluster>.cloud.qdrant.io:6333\"\n",
        "QDRANT_API_KEY = \"\"      # e.g. \"qdrant_...\"\n",
        "\n",
        "# Apply pasted credentials if provided; otherwise keep existing env/.env values.\n",
        "if OPENROUTER_API_KEY.strip():\n",
        "    os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY.strip()\n",
        "elif not os.environ.get(\"OPENROUTER_API_KEY\"):\n",
        "    os.environ[\"OPENROUTER_API_KEY\"] = \"sweep-placeholder-not-used\"\n",
        "\n",
        "if QDRANT_URL.strip():\n",
        "    os.environ[\"QDRANT_URL\"] = QDRANT_URL.strip()\n",
        "if QDRANT_API_KEY.strip():\n",
        "    os.environ[\"QDRANT_API_KEY\"] = QDRANT_API_KEY.strip()\n",
        "\n",
        "if not os.environ.get(\"QDRANT_URL\") or not os.environ.get(\"QDRANT_API_KEY\"):\n",
        "    raise ValueError(\n",
        "        \"Missing Qdrant credentials. Paste QDRANT_URL and QDRANT_API_KEY in this cell or set them in .env.\"\n",
        "    )\n",
        "\n",
        "QUESTIONS_PATH = ROOT_DIR / \"eval\" / \"questions.jsonl\"\n",
        "OUT_PATH = ROOT_DIR / \"eval\" / \"retrieval_sweep_results.json\"\n",
        "\n",
        "# Optional: set to an int like 20 for a quick dry run\n",
        "SAMPLE_SIZE = None"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "eff91d7f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reuse production sweep helpers so notebook and script stay in parity.\n",
        "from scripts.sweep_retrieval_thresholds import (\n",
        "    apply_combo_to_chain,\n",
        "    evaluate_combo,\n",
        "    load_questions,\n",
        "    precompute_candidates,\n",
        ")\n",
        "\n",
        "print(\"Loaded sweep helpers from scripts/sweep_retrieval_thresholds.py\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "80adb690"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Preferred Colab execution path: run production sweep script directly.\n",
        "import subprocess\n",
        "\n",
        "# Skip full index scroll validation in Colab for speed.\n",
        "os.environ[\"SWEEP_SKIP_INDEX_SCAN\"] = \"0\"\n",
        "if SAMPLE_SIZE:\n",
        "    os.environ[\"SWEEP_SAMPLE_SIZE\"] = str(SAMPLE_SIZE)\n",
        "else:\n",
        "    os.environ.pop(\"SWEEP_SAMPLE_SIZE\", None)\n",
        "\n",
        "result = subprocess.run(\n",
        "    [\"python\", \"scripts/sweep_retrieval_thresholds.py\"],\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        ")\n",
        "print(\"RETURN CODE:\", result.returncode)\n",
        "print(\"STDOUT:\\n\", result.stdout)\n",
        "print(\"STDERR:\\n\", result.stderr)\n",
        "result.check_returncode()\n",
        "\n",
        "with open(OUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    rows = json.load(f)\n",
        "\n",
        "print(f\"Saved: {OUT_PATH}\")\n",
        "print(\"Top 5 configurations:\")\n",
        "for row in rows[:5]:\n",
        "    print(row)\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "552f8600"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "\n",
        "- For a quick pass, set `SAMPLE_SIZE = 20` first.\n",
        "- For final tuning, set `SAMPLE_SIZE = None`.\n",
        "- The execution cell runs the production script directly to avoid notebook drift.\n",
        "- `SWEEP_SKIP_INDEX_SCAN=0` is set in-notebook to include index validation.\n",
        "- Copy the best row values into your `.env` or `Settings` defaults after validation."
      ],
      "id": "8d01b5c9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}